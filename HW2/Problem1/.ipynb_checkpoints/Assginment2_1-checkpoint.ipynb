{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get all files name under path\n",
    "\n",
    "Args:\n",
    "    path: folder path to retrieve files' name.\n",
    "    ratio: propotion of training data. Default value is 1 (100%).\n",
    "    suffix: type of files\n",
    "    shuffle: a boolean value. TRUE: shuffle list; False: order list.\n",
    "\n",
    "Returns:\n",
    "    filesName: a list of all files end with suffix. For example:\n",
    "\n",
    "    [\"dir/a.txt\", \"dir/b.txt\"].\n",
    "\"\"\"\n",
    "def getFilesName( path, ratio = 1, suffix = \".txt\", shuffle = False ):\n",
    "    print( \"Retrieving files name from folder %s...\" % ( path ) )\n",
    "    filesName = []\n",
    "    files = os.listdir( path )\n",
    "    for file in files:\n",
    "        if os.path.splitext( file )[1] == suffix:\n",
    "            name = ''.join( [path, file] )\n",
    "            filesName.append( name )\n",
    "    if shuffle:\n",
    "        random.shuffle( filesName )\n",
    "    else:\n",
    "        filesName.sort()\n",
    "    return filesName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get content from files\n",
    "\n",
    "Extract all sentences from files, which words are less than\n",
    "or equal to 50 and return a list containing all of them.\n",
    "\n",
    "Args:\n",
    "    filesName: a list of all files containing contents.\n",
    "    encoding: the encoding of all files.\n",
    "\n",
    "Returns:\n",
    "    contents: a list of string contains all sentences.\n",
    "\"\"\"\n",
    "def getContents( filesName, encoding = \"UTF-8\" ):\n",
    "    print( \"Extracting contents...\" )\n",
    "    contents = []\n",
    "    for fileName in filesName:\n",
    "        with open( fileName, 'r', encoding = encoding ) as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                words = line.split()\n",
    "                length = len( words )\n",
    "                # Some lines contain only a '.' or even nothing.\n",
    "                if 2 <= length and length <= 50:\n",
    "                    contents.append( line.strip() )\n",
    "                line = f.readline()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write contents to files\n",
    "\n",
    "Write contents to specific files.\n",
    "\n",
    "Args:\n",
    "    contents: a list of string contains all sentences.\n",
    "    savePath: path that contents will save in.\n",
    "    fileName: the file name that contents will save to.\n",
    "\n",
    "Returns:\n",
    "    None.\n",
    "\"\"\"\n",
    "def writeContents( contents, savePath = \"./save/\", fileName = \"sentences.txt\",\n",
    "                   encoding = \"UTF-8\" ):\n",
    "    print( \"Writing contents to \" + savePath + fileName + \"...\" )\n",
    "    if not os.path.isdir( savePath ):\n",
    "        os.makedirs( savePath )\n",
    "    with open( savePath + fileName, 'w', encoding = encoding ) as f:\n",
    "        for content in contents:\n",
    "            if content[-1] != '.' and content[-1] != '?':\n",
    "                content += \".\"\n",
    "            f.write( content + \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parse \n",
    "\"\"\"\n",
    "def parse( inputFileName, saveFileName = \"output\" ):\n",
    "    print( \"Parsing\" )\n",
    "    sh_pos = ['\"./lexparser-POS.bat\"', '\"' + \"../../Problem1/save/\" + inputFileName + '\"',\n",
    "              '> ', '\"' + \"../../Problem1/save/\" + saveFileName + '-POS\"']\n",
    "    sh_pen = ['\"./lexparser-PEN.bat\"', '\"' + \"../../Problem1/save/\" + inputFileName + '\"',\n",
    "              '> ', '\"' + \"../../Problem1/save/\" + saveFileName + '-PENN\"']\n",
    "    sh_dep = ['\"./lexparser-DEP.bat\"', '\"' + \"../../Problem1/save/\" + inputFileName + '\"',\n",
    "              '> ', '\"' + \"../../Problem1/save/\" + saveFileName + '-DEPENDENCY\"']\n",
    "    ret_pos = subprocess.Popen( ' '.join( sh_pos ), shell = True,\n",
    "                                  cwd = \"../Tools/stanford-parser-full-2018-10-17/\" )\n",
    "    ret_pen = subprocess.Popen( ' '.join( sh_pen ), shell = True,\n",
    "                                  cwd = \"../Tools/stanford-parser-full-2018-10-17/\" )\n",
    "    ret_dep = subprocess.Popen( ' '.join( sh_dep ), shell = True,\n",
    "                                  cwd = \"../Tools/stanford-parser-full-2018-10-17/\" )\n",
    "    ret_pos.wait()\n",
    "    ret_pen.wait()\n",
    "    ret_dep.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbPercentage( fileName, encoding = \"UTF-8\" ):\n",
    "    verbs = {}\n",
    "    with open( fileName, 'r', encoding = encoding ) as f:\n",
    "        line = f.readline()\n",
    "        total = 0\n",
    "        cnt = 0\n",
    "        while line:\n",
    "            if line.strip():\n",
    "                cnt += 1\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                word_tag = word.split( '/' )\n",
    "                if len( word_tag ) == 2 and word_tag[1][0] == \"V\":\n",
    "                    if word_tag[1] not in verbs:\n",
    "                        verbs[word_tag[1]] = 1\n",
    "                    total += 1\n",
    "            line = f.readline()\n",
    "    return total / cnt, list( verbs.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noOfSentenceParsed( fileName, encoding = \"UTF-8\" ):\n",
    "    with open( fileName, 'r', encoding = encoding ) as f:\n",
    "        cnt = 0\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line.strip()[:5] == \"(ROOT\":\n",
    "                cnt += 1\n",
    "            line = f.readline()\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     filesName = getFilesName( \"../Data/corpus/\" )\n",
    "#     contents = getContents( filesName )\n",
    "#     writeContents( contents )\n",
    "#     parse( \"sentences.txt\" )\n",
    "    print( verbPercentage( \"./save/output-POS-UTF8\" ) )\n",
    "    print( noOfSentenceParsed( \"./save/output-PENN-UTF8\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.597727750894172, ['VBD', 'VBN', 'VBZ', 'VB', 'VBG', 'VBP'])\n",
      "14259\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
